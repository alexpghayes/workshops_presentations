---
author: "Alex Hayes"
title: "Journal Club: SuperLearner"
subtitle: "by Mark van der Laan, Eric Polley and Alan Hubbard (2007)"
date: "`r Sys.Date()`"
output:
  beamer_presentation:
    keep_tex: no
    theme: metropolis
    slide_level: 2
    incremental: no
fontsize: 12pt
classoption: compress
header-includes:
  \setbeamercolor{frametitle}{bg=gray}
  \hypersetup{colorlinks,citecolor=orange,filecolor=red,linkcolor=brown,urlcolor=blue}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Motivation

We want to combine multiple models together in a way that achieves minimum prediction error. How do we do it?

## Answer: stacking

1. Split the original data $X$ into $k$ folds
2. For each fold:
  - Train each model on the other folds
  - Use this trained model to predict on the current fold
3. Aggregate the predictions on held out folds into new matrix $Z$.
4. Train a *metalearner* on $Z$.

To predict on new data:

1. Run data through each of the models in the ensemble
2. Use these predictions to create $Z'$
3. Run $Z'$ through the metalearner

## Optimality result: English

> The super learner performs as well (in terms
of expected risk difference) as the oracle selector, up to a typically second
order term. 

If one of the candidate models is a correctly specified parametric model, the Super Learner acheives the "almost parametric" rate of convergence ${\log n \over n}$. Otherwise it performs asymptotically as well as the best possible combination of models.

## Optimality result: Math

\begin{center}
\includegraphics[scale=0.65]{super_learner_theorem_1.PNG}
\end{center}

## What are assumptions A1 and A2?

A1: The loss function $L(O, \psi) = (Y - \psi(X))^2$ is uniformly bounded

A2: The variance of $\psi_0$ centered loss function $L(O, \psi) - L(O, \psi_0)$ can be bounded by its expectation uniformly in $\psi$

## Extension + Question

The *Subsemble* algorithm by Erin LeDell is less computationally expensive but achieves the same optimality via partitioning data out to each candidate learner

Why does you have you use V-Fold cross validation instead of, say, the bootstrap?

Paper available at [goo.gl/UrxnT7](http://goo.gl/UrxnT7)
